% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper}
%%% PACKAGES
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{url}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{sidecap}
\graphicspath{ {./res/} }

%%% HEADERS & FOOTERS
\usepackage{fancyhdr}
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape}

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}%
\DeclarePairedDelimiter\fract{fract(}{)}
\newcommand{\code}{\texttt}

\renewcommand{\listfigurename}{Index des illustrations}

% Custom ParFor (parallel for) command in algorithms
\algblock{ParFor}{EndParFor}
\algnewcommand\algorithmicparfor{\textbf{parfor}}
\algnewcommand\algorithmicpardo{\textbf{do}}
\algnewcommand\algorithmicendparfor{\textbf{end\ parfor}}
\algrenewtext{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicpardo}
\algrenewtext{EndParFor}{\algorithmicendparfor}

%%% END Article customizations


\title{Rapport de projet\\Génération de terrain et affichage 3D}
\author{Van Hollebeke Joshua\\Calais Albin}
\begin{document}
\maketitle

\section{Avant propos} 

Notre projet consiste à créer un générateur de terrain et à afficher ce terrain d'une manière réaliste. Pour cela nous développerons des algorithmes de génération, des interfaces de dialogue avec le gpu et des systèmes d'affichage très complexes.

Ce projet sera écrit en C++ pour permettre une gestion avancé de la mémoire et des performances, il facilitera aussi l'utilisation de l'api graphique OpenGL.
Nous utiliserons plusieurs algorithmes connus et d'autres tirés de papiers de recherche, nous en concevrons et adapterons certains car notre cas d'utilisation est assez particulier.

La plupart des systèmes que nous construirons existent déjà mais nous essayerons d'y apporter des améliorations.

\paragraph{}
Pour les systèmes existants, nous utiliserons la terminologie anglaise plutôt que française.

\section{Conception et gestion de projet}

D'un point de vue global notre projet est assez simple, il se compose seulement de deux modules de haut niveau qui utilisent chacun plusieurs modules de plus bas niveau.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.6]{overview_uml}
	\caption{Diagramme de classes : composantes principales du projet}
\end{figure}

\subsection{Conception structurelle}

Nous avons passé un certain temps en amont sur la concéption globale de l'application. Elle ressemble à ce qu'on trouverait dans un \textit{Game Engine} moderne du type Unity ou Unreal Engine. Il existe une unique \textit{scène} - un monde - qui contient des objets qui sont affichés et mis à jours régulièrement.

La scène est construite une seule fois et le joueur y existe et peut s'y balader. La scène est globalement statique, les seuls objets qui se déplacent sont le joueur et le soleil, le reste est figé en place mais peut être animé d'autres manières.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{detailed_structure_uml}
	\caption{Diagramme de classes : composantes détaillées}
\end{figure}

\subsection{Tests, sandbox}

Ce genre de projet est très peu propice aux tests, pour s'assurer du bon fonctionnement global de l'application nous nous baserons sur des tests d'intégration seulement. Pour chaque fonctionnalité nous créerons une scène qui présentera seulement la fonctionnalité en question, de cette manière il sera très simple de vérifier le bon fonctionnement de chaque partie du système.

En plus de ces scènes de test, nous créérons des scènes \textit{sandbox} qui intégreront toutes les fonctionnalités et serviront de démonstration techniques des résultats que nous obtiendrons. Voici la liste des scènes finales, dans l'ordre dans lequel nous les avons créé (il manque celles qui ont été retirées pendant le développement).

\paragraph{}
\begin{tabular}{|l|l|}
	\hline
	Nom de la scène & Fonctionnalité \\\hline\hline
	\code{TestCameras} & Caméra perspective, orthographique, champ de vision\\\hline
	\code{TestShaders} & \hyperref[sec:shaders]{Vertex Shader et Fragment Shader}\\\hline
	\code{TestSky} & \hyperref[sec:sky]{Cubemap}, nuages\\\hline
	\code{TestTerrain} & \makecell[l]{Scène de tests principale, génération de terrain, érosion,\\ fonctions de bruit, brouillard}\\\hline
	\code{TestFB} & \hyperref[sec:framebuffers]{Frame buffer}, effets spéciaux\\\hline
	\code{TestComputeShader} & \hyperref[sec:shaders]{Compute shader}\\\hline
	\code{TestShadows} & \hyperref[sec:casted_shadows]{Ombres portées}, caméra orthographique, depth map\\\hline
	\code{TestInstanced} & \hyperref[sec:instanced_rendering]{Instanced rendering}, affichage de l'herbe\\\hline
	\code{TestWater} & Réflexion, réfraction\\\hline
	\code{POC1} & Intégration - terrain, ombres\\\hline
	\code{POC2} & Intégration - terrain, herbe\\\hline
	\code{POC[3,4]} & Intégration - démonstrations de différents types de terrain\\\hline
\end{tabular}

\section{Génération de terrain}

Pour générer notre terrain, il nous faut d'abord lister les contraintes que nous nous fixons - et celles que nous ignorons - ; nous voulons :
\begin{itemize}
	\item{un grand terrain}
	\item{sans répétitions}
	\item{assez détaillé}
	\item{dont la hauteur change}
\end{itemize}

Nous nous restreindrons à une seule valeur de hauteur par position dans le plan, donc pas de grottes ou de surplomb. Les algorithmes classiques qui correspondent à ces critères consistent à créer une \textit{carte de hauteur} (\textit{heightmap}) et à placer des points sur une grille dont les hauteurs correspondent à celles de la carte. Il suffit ensuite de relier ces points pour avoir un terrain convainquant comme illustré par la figure \ref{fig:wireframe_terrain}. L'objet généré s'appelle un \textit{Mesh}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{terrain_wireframe}
	\caption{Un mesh de terrain fait à partir d'une grille élevée}
	\label{fig:wireframe_terrain}
\end{figure}

Ici on a relié les points par des segments mais de manière générale on dessinera des triangles pleins.

Il existent d'autres méthodes pour faire ce genre de terrain (cubemarching, raymarching avec génération dynamique...) qui permettent de faire plus mais qui sont beaucoup plus gourmandes en performances et en complexité. Dans notre cas une heightmap est beaucoup plus adaptée.

\subsection{Bruit de Perlin}

Pour créer la heightmap il nous faut ce qu'on appelle un \textit{bruit}, une fonction dont le domaine de définition est le plan $xz$ et le domaine de valeurs est $\mathbb{R}$. Cette fonction doit être pseudo-aléatoire mais deterministe. La plus simple est le \textit{white noise} qui est "complètement aléatoire"\footnote{On utilisera le générateur de nombre pseudo-aléatoires de C++ pour attribuer une valeur à chaque point du plan $\mathbb{Z}^2$.}. On s'interessera plutôt aux fonctions de bruit continues sur $\mathbb{R}^2$.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{white_noise}
	\includegraphics[scale=.49]{perlin_noise}
	\caption{White noise et Perlin noise}
	\label{fig:noises}
\end{figure}

Les fonctions les plus communes pour une génération de ce style sont de la famille des \textit{Gradient noise} (bruit de gradient) et \textit{Value noise} (bruit de valeur).
Un value noise est défini à partir d'un white noise de cette manière :

\begin{alignat*}{3}
	V(x,y) =f( &f(B(\floor{x},\floor{y}), &&B(\floor{x+1},\floor{y}), &&\fract{x}),\\
			&f(B(\floor{x},\floor{y+1}), &&B(\floor{x+1},\floor{y+1}), &&\fract{x}),\\
			&\fract{y})
\end{alignat*}

Ici $V$ est le value noise, $B$ est le white noise et $fract(x)$ est la partie fractionaire de $x$. $f$ dépend du value noise, c'est une fonction d'interpolation, la plus simple est l'interpolation linéaire\footnote{$lerp(a,b,x) = a+(b-a)*x$}.
L'idée est d'interpoler entre des valeurs complétement aléatoires selon une grille. Le value noise permet de générer des heightmaps très simplement, mais qui laissent à désirer. Aujourd'hui il a été très largement remplacé par le bruit de Perlin, qui est un cas spécifique de gradient noise.

La différence avec le value noise est qu'au lieu d'utiliser un white noise comme base, on génère à la place une grille de vecteurs unitaires et pour calculer les "$B(x,y)$" on calcule le produit scalaire du point $(x,y)$ à l'intérieur de sa cellule sur la grille avec les vecteurs unitaires :

\begin{align*}
	fx&=\floor{x} & a_{00}&=<(dx,dy), U_{fx,fy}>\\
	fy&=\floor{y} & a_{10}&=<(dx-1,dy), U_{fx+1,fy}>\\
	dx&=\fract{x} & a_{01}&=<(dx,1-dy), U_{fx,fy+1}>\\
	dy&=\fract{y} & a_{11}&=<(1-dx,1-dy), U_{fx+1,fy+1}>
\end{align*}
\begin{alignat*}{3}
	G(x,y) =f( &f(a_{00}, &&a_{01}, &&dx),\\
			&f(a_{10}, &&a_{11}, &&dx), dy)
\end{alignat*}

Dans son article\cite{perlinnoise}, Ken Perlin défini le \textit{Simple gradient noise} avec $f$ l'interpolation linéaire, et le bruit de perlin, avec $f$ la fonction $smoothstep$\footnote{$smoothstep(a,b,x) = 3x^2-2x^3$}.

Ces bruits sont bons pour un terrain simpliste, mais l'astuce de Ken Perlin est d'en cumuler plusieurs octaves. En jouant sur la fréquence et l'amplitude de chacune :
\begin{align*}
	Height(x,y) = \sum_{k=1}^{N}&Amplitude_k G(Frequency_k*(x,y))\\
	Amplitude_k &= Persistence^k\\ 
	Frequency_k &= Lacunarity^k
\end{align*}
Les paramètres qui nous restent à contrôler sont la persistance (le facteur de taille entre deux octaves), la lacunarité (le facteur de poids entre deux octaves) et le nombre d'octaves. Avec ceci on arrive à des cartes de hauteur assez réalistes, comme illustré en figure \ref{fig:layered_noise}. À noter que dans certains cas on préfèrera définir les amplitudes et fréquences par octave sans utiliser de persitance ou lacunarité.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.3]{perlin_1_octave}
	\includegraphics[scale=.3]{perlin_2_octaves}
	\includegraphics[scale=.3]{perlin_4_octaves}
	\caption{1, 2 et 4 octaves du Perlin noise}
	\label{fig:layered_noise}
\end{figure}

\subsubsection{Nuages}
Dans ce projet la première utilisation des fonctions de bruit est la génération du terrain, mais leurs utilités ne s'arrêtent pas ici. Une autre application évidente est la génération de nuages, on peut agrandir une de ces images, la placer au dessus du joueur et utiliser le niveau de blanc comme un niveau de transparence pour avoir des nuages très facilement. On peut même faire se déplacer les nuages en ajoutant un facteur $+Displacement_{k}$ à chaque octave avant d'appliquer $G$, en utilisant des facteurs plus importants pour les hautes octaves on obtient vite une animation de vent convaincante.

\subsection{Erosion}

On peut rendre le bruit généré plus réaliste encore en appliquant des propriétés physiques naturelles, la première à laquelle on pense est l'érosion.

L'idée est de simuler un très grand nombre de gouttes d'eau qui dévallent les pentes en arrachant du sédiment du terrain et en la relachant en aval. L'algorithme que nous utiliserons est expliqué dans la thèse de Hans Theobald Beyer\cite{erosion}.
Dans le code cela consiste à calculer une suite de valeurs de gradient de la heightmap pour déplacer les gouttes selon la pente, et à chaque déplacement on calcule la quantité de sédiment à arracher ou déposer. Le seul bémol est que le dépot et l'érosion ne se font pas seulement à la position de la goutte, mais aussi aux alentours. Pour ne pas recalculer les différences à chaque étape de chaque goutte on fait le calcul en amont, qu'on stoque pendant toute la durée de l'algorithme. Cela peut poser certains problèmes de performance et de besoin en mémoire, l'espace mémoire nécessaire est en $O(n^2)$ avec la taille du terrain et le premier facteur du polynôme est très important.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.4]{erosion_before}
	\includegraphics[scale=.4]{erosion_after}
	\caption{Comparaison avant/après application de l'érosion}
	\label{fig:erosion_comparison}
\end{figure}

\subsection{Structure du terrain}

On verra ensuite que penser à l'affichage du terrain avant de fixer sa structure est essentiel, avec une bonne structure l'affichage est plus simple et beaucoup plus performant. L'idée est que les données du terrain ne peuvent pas (ou peu) être modifiées pendant l'exécution mais qu'elle doivent pouvoir être segmentées pour n'en afficher qu'une partie.
Pour résoudre ce problème nous divisons le terrain en parcèles (\textit{chunks}). Chaque parcelle peut être générée et affichée indépendament des autres, seul sa position suffit à savoir ce qu'elle contient.
Avec cette division il est assez simple de faire un terrain qui se met à jour en fonction de la position du joueur, pour que les chunks proches soient toujours visible.

%% classes



\subsection{Variations}

Avant de générer le mesh du terrain on peut modifier la heightmap pour obtenir différents résultats, on peut même ne pas utiliser les fonctions de bruit et la générer completement différemment.

\begin{itemize}
	\item{À partir d'un bruit de Perlin de paramètres $N=2$ $Amplitude=[1, .5]$ $Frequency=[.3, .15]$ et en appliquant $h\rightarrow H-\abs{2x-H}$ on obtient un terrain qui ressemble aux dunes d'un desert.}
	\item{Dans une de nos scènes de démonstration nous appliquons $(x,y)\rightarrow Perlin(x,y)+\frac{S}{8}(\abs{x-\frac{S}{2}}+\abs{y-\frac{S}{2}})$ pour abaisser le terrain au centre sans que ce soit trop visible, simplement pour qu'à un bout de la carte on puisse voir d'avantage.}
	\item{On peut récupérer des cartes de hauteur de zones géographiques existantes (on en trouve sur internet\footnote{\url{https://tangrams.github.io/heightmapper}}).}
	\item{Avec un peu plus d'effort on peut créer des plateaux et arriver à une génération ressemblant aux Mesa}
\end{itemize}

Des illustrations de ces variations peuvent être trouveés plus loin\ref{fig:final}.


\section{Affichage 3D}

L'affichage représente la plus grosse partie du projet, on a beau avoir un terrain immense et avec des details très fins, s'il est impossible de l'afficher le tout n'a plus grand interet.

Nos contraintes principales seront de pouvoir afficher un très grand terrain, avec des performances qui permettent le déplacement en temps réel (60 images par secondes). Concrètement cela veut dire qu'afficher une image doit prendre moins de 16.6ms, ce qui peut être très difficile à respecter dans certains cas.

Avec ces considérations et notre experience passée commune, nous avons choisi d'utiliser OpenGL comme interface avec le gpu (carte graphique).

\subsection{OpenGL}

OpenGL est une spécification qui définie des points d'entrée d'une interface cpu-gpu. Pour utiliser OpenGL nous avons besoin d'une librairie dépendante du langage de programmation ; en c++ nous utiliserons glad. Nous aurons aussi besoin de librairies pour la gestion de la fenêtre de l'application et l'interface utilisateur, nous utiliserons glfw et ImGui.

\paragraph{}
OpenGL fonctionne comme une \textit{state machine}. Chaque fonction modifie l'état interne du gpu et certaines lances des commandes à exécuter comme l'affichage de formes géométriques.
Il est important de mentionner que les gpu modernes ne savent pas afficher autre chose que des triangles et des lignes, pour afficher un rectangle on devra se contenter de dessiner deux triangles.

\subsection{Shaders}
\label{sec:shaders}

Les \textit{shaders} sont des programmes qui tournent sur le gpu plutot que sur le cpu. Nous utiliserons extensivement deux types de shaders pour l'affichage : le \textit{vertex shader} qui s'execute pour chaque sommet des triangles affichés ; et le \textit{fragment shader} qui s'execute pour chaque pixel couvert par le triangle. Des shaders classiques ressemblent à la figure \ref{fig:vs_fs_shaders}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.2]{vertex_sample}
	\includegraphics[scale=.2]{fragment_sample}
	\caption{Exemple de Vertex Shader et Fragment Shader}
	\label{fig:vs_fs_shaders}
\end{figure}

Un dernier type de shader que nous utiliserons est le \textit{compute shader}, qui ne sert pas à l'affichage mais permet de faire des calculs massivement parrallèles sur le gpu. Il nous sera utile pour gagner en performance.
\par
Chaque shader prend des entrées différentes, ce qui est commun à tous c'est la notion d'\textit{uniform} : des variables globales qui peuvent être changées seulement entre deux appels à des fonctions d'affichage/d'exécution de compute shader.
Avec ces éléments définis on peut faire un schéma de la "pipeline OpenGL"  comme illustré en figure \ref{fig:opengl_pipeline}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.3]{opengl_pipeline}
	\caption{Schéma de la pipeline OpenGL}
	\label{fig:opengl_pipeline}
\end{figure}

\subsection{Repères, caméras et mathématiques}

Avant de pouvoir afficher quoique ce soit à l'écran, il nous faut des données à afficher (Vertex Buffer et Index Buffer, nous y reviendrons \hyperref[sec:instanced_rendering]{plus tard}), des shaders pour définir \textit{comment} l'afficher et aussi bien comprendre comment placer les triangles à l'écran.
Par défaut OpenGL utilise un \textit{viewport} (un espace virtuel d'affichage) compris entre $-1$ et $1$ en $x$ et $y$ et entre $0$ et $1$ pour $z$. Cela signifie que la position générée par le Vertex Shader doit être comprise dans cet interval pour que le pixel associé être affiché (le vertex shader définit la position des sommets, les positions des pixels du triangle en sont déduit). Un sommet de coordonnées $(-1,-1,0)$ est affiché en haut à gauche de l'écran et un sommet $(1,1,0)$ est affiché en bas à droite. La coordonnée $z$ est utilisée pour la profondeur.
\par
Nous définierons deux repères supplémentaires, celui du monde (dans $\mathbb{R}^3$) et celui des modèles (dans $\mathbb{R}^3$). Imaginons qu'on veuille afficher le modèle d'un arbre, on va d'abord créer les sommets dans le repère du modèle (centré en $(0,0,0)$, aux dimensions 1:1), on le transformera pour passer dans le repère du monde (d'abord une mise à l'echelle puis une translation pour le placer au bon endroit) et enfin on le projetera sur le viewport, la projection dépendra du type de caméra qu'on utilisera.
Un gros avantage de cette méthode est que toutes ces transformations sont des opérations de projection d'un espace à un autre, qu'on peut donc les décrire avec des multiplications de matrices. En mémoire il nous suffira de conserver les positions dans le repère du modèle et les deux matrices de changement de repère.

\paragraph{}
Un exemple : on veut doubler la taille d'un modèle puis le déplacer de deux unités dans le sens $+x$, on applique la transformation suivante à chacun de ses points.
$$
	P = \begin{pmatrix}x\\y\\z\\1\end{pmatrix}\\
	A = \begin{pmatrix}2&0&0&0\\0&2&0&0\\0&0&2&0\\0&0&0&1\end{pmatrix}\\
	B = \begin{pmatrix}1&0&0&2\\0&1&0&0\\0&0&1&0\\0&0&0&1\end{pmatrix}\\
$$
$$
	BAP = \begin{pmatrix}2x+2\\2y\\2z\\1\end{pmatrix}
$$

\begin{wrapfigure}{R}{0.3\textwidth}
	\begin{center}
	\includegraphics[scale=.2]{coordinate_systems}
	\end{center}
	\caption[Résumé des repères]{Résumé des repères\\\url{https://www.aosabook.org/en/500L/a-3d-modeller.html}}
	\label{fig:coordinate_systems}
\end{wrapfigure}

Ici $A$ est une matrice de mise à l'echelle et $B$ est une matrice de translation, $C=BA$ serait la matrice de transformation (projection) du repère modèle au repère monde. La quatrième coordonnée est utilisée pour faciliter le calcul des translations, elle vaudra toujours $1$ pour les points et $0$ pour les vecteurs même s'il est plus rare de faire ces projections sur des vecteurs.


\paragraph{}
La projection du monde vers le viewport est un peu plus compliquée, il existe deux types principaux de projection qui sont les projections perspective et orthographique. Elles possèdent chacune une écriture matricielle que nous ne détaillerons pas mais qui peuvent se retrouver assez facilement avec un peu d'algèbre linéaire. Cette projection seule ne suffit pas, tel quel notre caméra devrait toujours être placée à l'origine du monde et être dirigée selon l'axe $+x$...
\par
Une astuce pour prendre en compte la position de la caméra est d'appliquer une transformation au repère du monde qui projète la caméra à l'origine et dirigée vers $+x$, de cette manière nous n'avons pas à modifier la dernière projection. Par exemple si la caméra est située en $(2,3,4)$ on appliquera $(x,y,z)\rightarrow(x-2,y-3,z-4)$ à tous les points avant de les projeter sur le viewport (ici on ne tient bien sûr pas compte de la rotation de la caméra).

\paragraph{}
Pour finir on retient trois matrices de projection :
\begin{itemize}
	\item{$M$ ("model") qui transforme du modèle au monde}
	\item{$V$ ("view") qui annule la transformation de la caméra}
	\item{$P$ ("projection") qui projète du monde au viewport}
\end{itemize}

Ce modèle en trois matrices est le plus utilisé. Il suffit de donner $P'=PVM$ au Vertex Shader et lui laisser transformer chaque vertex. On notera d'ailleur qu'il suffit d'inverser $P'$ pour projeter des positions à l'écran à des positions dans le monde, on peut par exemple savoir où - dans le monde - l'utilisateur pointe lorsqu'il clique à l'écran\footnote{Le calcul est un peu plus compliqué, on passe de $\mathbb{R}^2$ à $\mathbb{R}^3$, il faut tirer un rayon depuis la position de la caméra en direction du point qu'on vient de calculer à partir de $P'^{-1}$ et trouver la première intersection avec un objet du monde.}.

\subsection{Ciel}
\label{sec:sky}

Pour afficher le ciel il existe un objet assez spécifique qui s'appelle \textit{cubemap}. L'idée est d'afficher autour du joueur une texture de ciel, on pourrait théoriquement le faire en affichant une sphère - c'est ce qui serait le plus naturel - mais puisque nous sommes restreint à dessiner des triangles cela impliquerait de dessiner un \textit{très} grand nombre de triangles. On utilise donc une cubemap, qui est une projection d'une texture sphérique sur un cube, on peut ensuite afficher un cube plutôt qu'une sphère autour du joueur. Le calcul de projection inverse est fait directement par OpenGL.

Une optimisation qu'on retrouve à plusieurs autres moments est d'afficher ce ciel \textit{après} avoir affiché tout le reste, cela ne semble pas naturel mais en affichant seulement là où rien d'autre n'a été affiché on est sûr de ne pas dessiner des pixels inutiles. Le résultat est apparent en figure \ref{fig:sky_depth_test}.

\begin{SCfigure}
	\centering
	\caption[Zone dessinée en ordonnant les affichages]{Zone dessinée en ordonnant les affichages\\La region dessinée (le ciel) ne couvre qu'une partie de l'écran, c'est autant de travail de moins pour le gpu}
	\includegraphics[scale=.45]{sky_depth_test}
	\label{fig:sky_depth_test}
\end{SCfigure}

\subsection{Ombres}

Nous avons implémenté deux types d'ombre : les ombres d'ambiance et les ombres portées. Les deux se combinent très facilement dans le fragment shader utilisé pour le terrain.
\subsubsection{Ombre d'ambiance}
Une ombre d'ambiance est l'obsurcissement des surfaces qui ne sont pas dirigées vers le soleil. Mathématiquement cela se calcule très bien à partir des normales du terrain, pour chaque pixel on calcule ce que reçoit le pixel :
$$ S_{ambiance}=max(0, \vec{N}\cdot \vec{D}) $$
Avec $\vec{N}$ la normale du terrain à la position du pixel, $\vec{D}$ la direction des rayons su soleil comme illustré dans la figure \ref{fig:ambiant_shadows_schema}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{ombres_ambiantes}
	\caption{Schéma du fonctionnement des ombres ambiantes}
	\label{fig:ambiant_shadows_schema}
\end{figure}

\subsubsection{Ombre portées}
\label{sec:casted_shadows}
Le calcul des ombres portées et autrement plus compliqué, et se divise en plusieurs étapes
\begin{enumerate}
\itemsep-.5em
\item positionner le soleil pour qu'il éclaire le moins possible
\item afficher la scène "depuis le point de vue du soleil"
\item afficher la scène normalement, en tenant compte de la distance des objets au soleil
\end{enumerate}

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{ombres}
	\caption{Schéma du fonctionnement des ombres portées}
	\label{fig:shadows_schema}
\end{figure}

L'idée est de calculer la distance des pixels au soleil et de vérifier que cette distance est bien la plus petite à la position du pixel du point de vue du soleil (en bleu et orange sur la figure \ref{fig:shadows_schema}), si ce n'est pas le cas cela signifie qu'un autre objet est plus proche du soleil et donc qu'il projète une ombre sur le pixel (en vert sur le schéma).

\paragraph{}
Le positionnement se fait en listant les objets qui doivent recevoir et pouvoir projeter des ombres. Tout les éléments qui ne sont pas dans le champ de vue du joueur n'ont pas à être éclairés mais ceux qui peuvent projeter des ombres sur des objets visibles doivent être pris en compte.

\begin{SCfigure}
	\centering
	\caption[Capture du positionnement de la caméra "soleil"]{Capture du positionnement de la caméra "soleil"\\Le trait rouge est la direction des rayons du soleil ; le plus grand pavé jaune est la zone visible par le joueur ; le pavé gris est la zone couverte par le champ de vision du soleil et les autres pavés sont en jaune s'ils n'influencent pas la position du soleil ou en rouge s'ils sont succeptibles de projeter une ombre sur la zone visible.}
	\includegraphics[scale=.49]{casted_shadows}
	\label{fig:sun_camera_position}
	\vspace{-10pt}
\end{SCfigure}

\paragraph{}
L'affichage de la scène depuis le point de vue du soleil utilise une caméra orthographique car tous les rayons sont perpendiculaires. La distance la plus faible est enregistrée pour chaque pixel et est utilisée ensuite. La distance enregistrée ainsi est normalisée (linéarisée dans $[0,1]$) par OpenGL. La texture qui contient ces distances est appellée \textit{depth map} (\textit{carte de profondeur}).

\begin{SCfigure}
	\centering
	\caption[Depth map]{Depth map\\Les zones blanches sont loins de la caméra, les zones foncées sont plus proche. Les valeurs réelles de distance dépendent de la configuration de la caméra.}
	\fbox{\includegraphics[scale=.25]{depth_map}}
	\label{fig:sun_depth_map}
	\vspace{-10pt}
\end{SCfigure}

Le calcul du positionnement de la caméra du soleil est la partie la plus compliquée de cet algorithme, nous ne le détaillerons pas ici mais le code peut être trouvé dans le fichier \code{SunCameraHelper.cpp}. Il s'agit surtout de projections de de calcul de \textit{bounding boxes} et \textit{bounding spheres}.

\subsubsection{Algorithme final}

Après que la depth map ai été calculée, on arrive à l'algorithme \ref{alg:shadows} pour calculer la quantité de soleil que reçoit chaque pixel.
\begin{algorithm}
\caption{Calcul des ombres par pixel}
\label{alg:shadows}
\begin{algorithmic}
\State $P_s \gets \text{... matrice de projection monde$\rightarrow$depth map}$
\State $DM \gets \text{... depth map 2D}$
\State $\vec{D} \gets \text{... direction des rayons du soleil}$
\\
\State $\vec{p} \gets \text{...  position 3D du pixel}$
\State $\vec{n} \gets \text{... normale 3D à la position du pixel}$
\\
\State $S_{ambiant} \gets max(0, \vec{n}\cdot \vec{D})$
\State $\vec{u} \gets P_s\times\vec{p}$
\State $d_{pixel} \gets \vec{u}.z$
\State $d_{nearest} \gets DM(\vec{u}.xy)\times(z_{far}-z_{near})+z_{near}$
\State $S_{casted} \gets smoothstep(-\epsilon, 0, d_{pixel}-d_{nearest})$
\State $Q \gets S_{ambiant}\times S_{casted}$
\\
\State $PixelColor\gets mix(SunDarkColor, SunLightColor, max(.1, Q\times SunStrength))$
\end{algorithmic}
\end{algorithm}

On préfère utiliser la fonction $smoothstep$ et utiliser $\epsilon$ plutôt que de mettre $S_{casted}$ à $0$ ou $1$ pour éviter le crénelage du aux erreurs d'arrondis. Le résultat de ces algorithmes peut être vu en figure \ref{fig:shadows}.

\begin{SCfigure}
	\centering
	\caption[Capture des ombres]{Capture des ombres\\Il reste quelques soucis de crénelage, il existe des solutions (\textit{multisampling}) mais puisque notre cas d'utilisation est d'afficher la silouete du terrain le crénelage n'est pas très génant.}
	\includegraphics[scale=.45]{shadows}
	\label{fig:shadows}
	\vspace{-10pt}
\end{SCfigure}

\subsection{Instanced rendering}
\label{sec:instanced_rendering}

En plus du terrain en lui même, nous avons choisi d'afficher quelques objets en plus. Et par "quelques" il faut entendre plusieurs millions. Nous nous sommes donné le but d'afficher des brins d'herbe, nous reviendrons sur les algorithmes d'optimisation mis en place mais avant de pouvoir en discuter il est important de comprendre \textit{comment} OpenGL gère l'affichage.
\paragraph{}
Pour afficher un objet simple (un cube par exemple) il nous faut 4 structures de données sur le gpu : un \textit{Vertex Buffer}, qui contient les données de chaque sommet du cube ; un \textit{Index Buffer}, qui définit les triangles à partir des sommets ; un shader et un \textit{Vertex Array} que nous passerons sous silence car ils n'influencent pas les données.

Une manière très naïve d'afficher un très grand nombre d'éléments est de construire un Vertex Buffer (VB) et un Index Buffer (IB) par objet. Le soucis est qu'à l'affichage il nous faudra changer le contexte OpenGL (modifier les VB/IB actifs) pour chaque élément, ce qui ralentit considérablement le tout\footnote{Le vrai problème vient du nombre d'appels à des fonctions d'affichage, il est possible d'afficher beaucoups d'éléments d'un coup mais seulement si le contexte n'a pas à changer}.
Si les objets sont identiques on peut n'utilser qu'un seul IB, mais ce n'est pas suffisant.

\paragraph{}
Une manière déjà plus intéressante est de construire un unique VB qui contient tout les sommets de tout les éléments et un IB qui contient les triangles constitués de ces sommets, cela améliore déjà considérablement les performances. Cette méthode est appellée \textit{batch rendering}.
Cette méthode possède cependant un désavantage majeur, il est quasiment impossible de n'afficher qu'une partie des éléments. Pour le terrain par exemple nous n'affichons que les chunks visibles par la caméra, le batch rendering n'est donc pas adapté. On préferera faire des chunks de grande taille pour diminuer le nombre de changement de contextes même si cela diminue l'éfficacité de n'afficher que les chunks visibles.

\paragraph{}
Dans notre cas on peut encore faire mieux, tout nos éléments sont identiques mis à part leurs position dans le monde, on peut donc utiliser un seul VB et IB qui contiennent les données d'un unique brin d'herbe et le dessiner autant de fois que nécessaire à des positions différentes. Mais pour ne pas avoir à modifier le contexte OpenGL il faut que ces données d'instances soient présentes sur le gpu. On créé donc un \textit{instance buffer} qui contient la position de chaque brin d'herbe. Cette méthode s'appelle l'\textit{instanced rendering}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.4]{grass_vbibib}
	\caption{Structures présentes sur le gpu en instanced rendering}
	\label{fig:grass_vbibib}
\end{figure}

\subsubsection{Profilage}
Avec l'instanced rendering on peut afficher plusieurs centaines de milliers de triangles sans trop impacter les performances, mais ce n'est pas suffistant pour les quelques millions que nous nous sommes fixé, nous reviendrons sur les deux optimisations majeures dans la section \ref{section:grass_rendering}.
\paragraph{}
 Pour vérifier que notre implémentation est déjà meilleure que la naïve on peut comparer le temps mit avec les deux méthodes. Le profilage doit se faire avec des outils adaptés et non pas depuis C++ car le gpu et le cpu ont des fils d'execution très différent\footnote{Nous utiliserons RenderDoc (\url{https://renderdoc.org/}) car il offre le plus d'outils compatibles avec OpenGL.}.

\begin{wrapfigure}{R}{0.3\textwidth}
	\begin{center}
		\includegraphics[scale=.4]{profiling}
	\end{center}
	\caption{Session de profiling avec RenderDoc}
	\label{fig:profiling}
\end{wrapfigure}

Le profilage répertorie l'enssemble des appels aux fonctions d'affichage (\code{glDrawXX}), les appels aux compute shaders (\code{glDispatchCompute}) et tous les appels de changement d'états (\code{glBindBuffer}, \code{glBindTexture}, \code{glUniformXX}... ces appels ont été masqués sur la figure \ref{fig:profiling} car leurs temps d'exécution est négligeable). Le temps d'exécution pour chaque fonction indiqué en $\mu$s et le temps total ne doit pas dépasser $10^6/60=16.\overline{6}\mu\text{s}$.

\subsection{Effets spéciaux}

%% TODO section effets spéciaux

\subsubsection{Frame Buffers} %% ...
\label{sec:framebuffers}



\section{Algorithmes spécifiques}

Dans cette section nous aborderons avec plus de détails les algorithmes que nous avons du développé et qui on représenté des défis techniques interessants.
%% algos qu'on a développé avec plus ou moins de sources (plutot moins que plus)

\subsection{Affichage de l'herbe}
\label{section:grass_rendering}

Nous avons déjà abordé l'instanced rendering dans la section \ref{sec:instanced_rendering}. Néanmoins pour afficher plusieurs millions de brins d'herbe d'autres techniques sont nécessaires. On peut déjà imaginer afficher deux modèles différents, un en haute résolution (\textit{HD}) de 7 ou 8 triangles et un en basse résolution d'un seul triangle (\textit{LD}) qui sera utilisé pour les brins d'herbes loin de la caméra. On peut aussi n'afficher que les brins d'herbe visible ; on ne peut pas replacer les brins d'herbe en permanence car l'envoi de données du cpu au gpu est lent, mais on peut dire au gpu de filtrer les brins d'herbe qui ne sont pas visible pour qu'ils ne fassent pas partie de la prochaine commande d'affichage.

\paragraph{}
La méthode que nous utiliserons pour filtrer les brins d'herbe visibles est inspirée de la vidéo d'Acerola\cite{grass_rendering}. L'idée est de maintenir deux instance buffers : le complet, qui contient tous les brins d'herbe et n'est mit à jours que lorsque le joueur se déplace beaucoup pour qu'il soit toujours au milieu de la zone couverte de brins d'herbe ; et un deuxième qui contient seulement les brins d'herbe visible et est mit à jours à chaque frame. L'algorithme s'appelle le scan and compact, une version parrallèle est l'algorithme \ref{alg:scan_and_compact}. Une connaissance préalable du calcul sur gpu est préférable pour comprendre cette section, expliquer le fonctionnement d'une carte graphique n'est pas du ressort de ce rapport.

\begin{algorithm}
\caption{Scan and compact}\label{alg:scan_and_compact}
\begin{algorithmic}
\State $I \gets \text{... instance buffer complet}$
\State $N \gets |I|$
\\
\State $V \gets \{0\}^N$ \Comment{Vote buffer}
\State $S \gets \{0\}^N$ \Comment{Scan buffer}
\State $B \gets \{nil\}^N$ \Comment{Compact buffer}
\State $M \gets 0$ \Comment{nombre total d'instances visibles}
\\
\ParFor{$i\gets 1, N$}
	\State $V_i \gets vote(I_i)$ \Comment{Vote, $V_i$ vaudra 1 ssi l'instance est visible}
\EndParFor
\State $S,M\gets Scan(V)$\Comment{Scan du vote buffer, cad $S_i\gets\sum_{k=1}^i V_k$}
\ParFor{$i\gets 1,N$}
	\If{$V_i=1$}
		\State $B_{S_i}\gets I_i$\Comment{Compact, les instances visibles remplissent $B$}
	\EndIf
\EndParFor
\end{algorithmic}
\end{algorithm}

L'avantage du gpu est que les calculs sont massivement parrallélisables. Nous avions vu l'algorithme de scan l'année dernière en CUDA en cours. Nous n'avons pas pu récuperer l'algorithme car OpenGL permet seulement de synchroniser les threads d'un groupe et pas les groupes entre eux et nous sommes limités en nombre de threads/groupes. Concretement cela implique que l'algorithme de scan doit se diviser en trois parties parallèles. Notre implémentation est inspirée du livre GPU Gems\cite{scan_algorithm}.

\paragraph{}
En étant limité à $N=1024$ threads/groupe et $G=1024$ groupes, l'algorithme que nous proposons est limité à $G\times N=1'048'576$ brins d'herbe, et peut facilement être étendu à $G\times N^M$ en répétant $M$ fois les étapes 2 puis 3.

\begin{tabular}{|l|c|l|}
	\hline
	 & $\makecell{Threads\times\\ Groupes}$ & action\\
	\hline
	1. scan/block & $N\times  G$ & \makecell[l]{On scanne sur $V_i$ chaque block de $N$ brins\\ d'herbe, le total de chaque block est\\ stoqué dans $A_i$}\\
	\hline
	2. scan/group & $G\times 1$ & \makecell[l]{On scanne sur $A_i$ les sommes de chaque\\ block, le total est stoqué dans $M$}\\
	\hline
	3. accumulation & $N\times G$ & \makecell[l]{On ajoute à chaque valeur de chaque block\\ (les $V_i$) la somme des sommes des\\ blocks précédents (les nouveaux $A_i$)}\\
	\hline
\end{tabular}

\paragraph{}
Le code de ces algorithmes peut être trouvé dans les fichiers sous \code{res/shaders/grass/}. Le code qui les invoque se trouve dans \code{src/World/Grass.cpp}.

\paragraph{}
On peut ensuite afficher $M$ brins d'herbe. Pour arriver aux plusieurs millions promis nous executons cet algorithme sur *deux* buffers, l'un sera affiché avec un modèle HD et le second avec un modèle LD. Il s'agit ensuite de modifier les deux instance buffers pour que les chunks proches de la caméra contiennent toujours des instances. On divise donc les deux instance buffers pour que chaque "case" contienne les instances d'un chunk. Il suffit de regénérer les cases des chunks qui changent de niveau de définition comme illustré en figure \ref{fig:grass_instance_buffers}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{grass_instance_buffers}
	\caption{Les deux instance buffers de l'herbe}
	\label{fig:grass_instance_buffers}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=.49]{grass_uml}
	\caption{Diagramme de classes : composantes du système de l'herbe}
\end{figure}

Il est à noter que les chunks de l'herbe ne correspondent pas aux chunks du terrain, les deux n'ont pas les mêmes contraintes ce qui fait que généralement les chunks de l'herbe sont beaucoup plus grands. Aussi, même si nous avons implémenté la génération continue de l'herbe, nous n'avons pas fait de même pour le terrain ; cette partie du projet serait facilement réalisable mais n'entrait pas dans nos priorités. Le résultat de ces algorithmes peut être observé en figure \ref{fig:grass}.

\begin{SCfigure}
	\centering
	\caption[Capture de l'herbe]{Capture de l'herbe\\Les brins d'herbe sont très gros ici, le résultat plus est satisfaisant au loin. L'herbe est animée (le vent la déplace). Il y a environ 1M3 brins d'herbe, et 6M triangles.}
	\includegraphics[scale=.35]{grass}
	\label{fig:grass}
\end{SCfigure}

\paragraph{}
Il est assez difficile de se représenter la quantité de travail à fournir pour afficher tout cela ; si on oublie la partie "filtre" en moyenne pour 2M brins d'herbes à afficher (1M HD et 1M LD) on a $10^6\times3\times7 + 10^6\times3\times1=24\times10^6$ appels du vertex shader. Tel qu'il est écrit le vertex shader calcule deux multiplications de matrices par appel\footnote{en réalité il fait aussi plusieurs calculs trigonométriques et bien plus d'additions/multiplications, sans compter les déplacements de valeurs en mémoire...}, pour environ 20 multiplications. Au total, le gpu doit traiter (beaucoup) plus de 500M multiplications par frame, et tout cela en moins de 16.6$\mu$s ! Avec les optimisations que nous avons apporté dans le cas idéal (quand aucun brin d'herbe n'est dans le champ de la caméra) chaque brin d'herbe est traité en un seul calcul, mais l'algorithme possède un coût incompressible non négligeable. On se rend bien compte de la difficulté que représente l'affichage d'autant d'objets. Ce serait complètement impossible sans gpu.

\subsection{Eau}

%% TODO section eau


\section{Résultats}

\begin{figure}[h]
	\centering
	\includegraphics[height=3cm]{final_trees}
	\includegraphics[height=3cm]{final_desert}
	\includegraphics[height=3cm]{final_mesa}
	\includegraphics[height=3cm]{final_mountains}
	\caption{Captures de nos différents résultats}
	\label{fig:final}
\end{figure}

Ces visuels peuvent être obtenus en utilisant le projet dans son état final et en écrivant un peu moins de 200 lignes chacun. Le projet totalise environ $11000$ lignes de c++ et $1500$ lignes de shaders, tout cela pour arriver à un niveau d'abstraction très satisfaisant.

\section{Pistes d'améliorations}

Notre travail peut s'utiliser tel quel, mais le projet pourrait être poursuivit de nombreuses manières. Nous en aborderons ici quelques unes qui nous ont parru important pendant le développement.

\subsection{Tessellation}

Le concept de \textit{tessellation} est propre à l'affichage de meshs complexes. L'idée est de répartir les vertex plus densément là où les détails sont plus importants et d'en économiser là où les détails sont moindres. Dans notre cas les vertex sont tous espacés également selon le plan $xz$ mais dès lors que les différences de niveau sont grandes on voit des artefacts apparaitre. Un exemple de tessellation appliquée à un mesh de la terre peut être trouvé en figure \ref{fig:tessellation_example}.
\par
On peut aussi utiliser la tessellation de manière dynamique, en diminuant la résolution des meshs qui sont loins de la caméra. Nous l'avons fait dans une moindre mesure avec l'herbe, mais l'appliquer au terrain serait très bénéfique. Ne serait-ce que pour afficher du terrain beaucoup plus lointain.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.4]{tessellation}
	\caption{Exemple de tessellation, les vertex sont plus denses dans les zones detailées\cite{tessellation}}
	\label{fig:tessellation_example}
\end{figure}

\subsection{Terrain}

Nous nous sommes focalisé sur la génération du relief du terrain, mais il reste beaucoup à faire pour créer un monde réaliste. Nous avons traité de l'eau et de l'herbe car ils représentaient des défis interessants mais rajouter des "\textit{features}" (arbres, batiments, etc...) Rajouter un système de gestion de ces features permormant n'est pas une mince affaire. Dans un premier temps on pourra se contenter de placer quelques modèles d'arbre dans le monde, dans un second temps on pourra les générer algorithmiquement, les animer et même concevoir un \textit{Entity Component System}\footnote{Un ECS est un système où chaque "objet" est un lien entre plusieurs composantes (physique, affichage...), chaque composante est stoquée avec les autres du même type, la hierarchie structurelle est très différente. Il est particulierement adapté au jeu vidéo.} si les performances l'exigent.

\par
Un problème que nous avons rencontré est l'application des textures. Nous sommes passé très vite sur le sujet mais chaque vertex possède des coordonnées \textit{uv} qui définissent la position du vertex sur une texture, notre problème vient du fait que les uvs sont calculés en fonction de la position $xz$ du vertex et ne tiennent pas compte de la hauteur. Sur des terrains très escarpés on a des artefacts importants qu'il est difficile de corriger.

\par
Une autre piste d'amélioration est la création de nuages réalistes. Nous nous sommes contenté d'utiliser astucieusement le perlin noise mais des techniques plus modernes à base de perlin noise 3D existent\footnote{SimonDev, "How Big Budget AAA Games Render Clouds", \url{https://youtu.be/Qj_tK_mdRcA}}. Avec ceci réalisé il serait facile d'ajouter de la brume dans des canyons par exemple.

\subsection{Physique}

Notre projet concernait seulement la génération et l'affichage, mais on peut voir facilement en quoi un moteur physique l'améliorerait. Nous avons déjà le calcul des normales et la séparation en chunks qui faciliteraient l'ajout d'un moteur physique mais le gros du travail reste à faire. Dans certaines scènes nous avons tout de même fait en sorte de simuler le déplacement du joueur sur le terrain mais notre méthode consiste seulement à replacer le joueur à une certaine distance au dessus du mesh, il n'y a pas de réaction physique - le joueur peut gravir des montagnes au même rythme qu'il marche dans les plaines -.

\subsection{Géometries différentes}

Un axe assez différent d'évolution possible est la génération et l'affichage d'un monde sphérique. On pourrait imaginer créer des planetes plutôt que des mondes plats. Ajouter ce type de génération demanderait de modifier la génération des meshs et d'adapter les heightmaps pour un pavage assez spécifique (la projection du plan à la sphère est assez compliquée de manière générale) mais le reste devrait pouvoir être conservé tel quel (ombres, reflexions, génération des reliefs...).

\paragraph{}
Une autre modification qui pourrait être apportée au mesh du terrain est la modification de la grille de base, nous l'avons faite carrée par soucis de simplicité mais il ne devrait pas être trop compliqué d'en faire une hexagonale. L'avantage d'une grille exagonale est que les détails sont répartis plus homogènement, la symétrie est mieux respectée alors que les triangles des carrés font apparaitre une seule des deux diagonales.

\subsection{Esthetiques différentes}

Nous avons choisi une esthetique qui se veut réaliste mais avec assez peu de changements on peut obtenir des visuels très différents.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.205]{esthetics_1}
	\includegraphics[scale=.2]{esthetics_2}
	\caption{Différentes variations d'esthetique}
	\label{fig:esthetics}
\end{figure}

On pourrait imaginer des visuels "low-poly" ou "toon" en diminuant le nombre de triangles et en rajoutant un shader "cel-shading\footnote{\url{https://en.wikipedia.org/wiki/Cel_shading}}".

\section{Conclusion}

%% TODO conclusion

\begin{thebibliography}{9}
\bibitem{perlinnoise}
Perlin, Ken. "Making Noise"

\bibitem{erosion}
Hans Theobald Beyer. "Implementation of a method for hydraulic erosion"

\bibitem{grass_rendering}
Acerola, "What I Did To Optimize My Game's Grass", \url{https://youtu.be/PNvlqsXdQic}

\bibitem{scan_algorithm}
GPU Gems 3, "Chapter 39. Parallel Prefix Sum (Scan) with CUDA", \url{https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda}

\bibitem{tessellation}
Sebastian Lague, "Trying to Improve My Geography Game with More Real-World Data", \url{https://youtu.be/UXD97l7ZT0w?t=989}
\end{thebibliography}

\listoffigures

\end{document}
